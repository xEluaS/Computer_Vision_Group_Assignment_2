{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "added some small augmentations. I want to change it to skewing instead of what i have now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "img_files = [f for f in os.listdir(\"/kaggle/input/kul-h02a5a-computer-vision-ga2-2024/train/img\") if not f.startswith(\".\")]\n",
    "\n",
    "n = len(img_files)\n",
    "\n",
    "train_files, validation_files = train_test_split(img_files, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "class SegmentationDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, img_folder, seg_folder, file_list, batch_size=32, image_size=(256, 256)):\n",
    "        self.img_folder = img_folder\n",
    "        self.seg_folder = seg_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.img_files = file_list\n",
    "        self.num_samples = len(self.img_files)\n",
    "        \n",
    "        # Initialize the ImageDataGenerator for data augmentation\n",
    "        self.datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            fill_mode=\"wrap\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.num_samples / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_img_files = self.img_files[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_imgs = []\n",
    "        batch_segs = []\n",
    "        \n",
    "        for img_file in batch_img_files:\n",
    "            img_path = os.path.join(self.img_folder, img_file)\n",
    "            seg_path = os.path.join(self.seg_folder, img_file)\n",
    "            \n",
    "            img = np.load(img_path, allow_pickle=True)\n",
    "            seg = np.load(seg_path, allow_pickle=True)\n",
    "            seg = tf.expand_dims(seg, axis=-1)\n",
    "            \n",
    "            img = resize(img, self.image_size)\n",
    "            seg = resize(seg, self.image_size, order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=False, anti_aliasing_sigma=None)\n",
    "            \n",
    "            seg = tf.keras.utils.to_categorical(seg, num_classes=21) if np.max(seg) < 21 else seg\n",
    "            \n",
    "            # Apply data augmentation\n",
    "            params = self.datagen.get_random_transform(img.shape)\n",
    "            img_aug = self.datagen.apply_transform(img, params)\n",
    "            seg_aug = self.datagen.apply_transform(seg, params)\n",
    "            \n",
    "            batch_imgs.extend([img, img_aug])\n",
    "            batch_segs.extend([seg, seg_aug])\n",
    "        \n",
    "        return np.array(batch_imgs), np.array(batch_segs)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "img_folder = \"/kaggle/input/kul-h02a5a-computer-vision-ga2-2024/train/img/\"\n",
    "seg_folder = \"/kaggle/input/kul-h02a5a-computer-vision-ga2-2024/train/seg\"\n",
    "batch_size = 10\n",
    "image_size = (256, 256)\n",
    "\n",
    "train_dataset = SegmentationDataset(img_folder, seg_folder, batch_size=batch_size, image_size=image_size, file_list=train_files)\n",
    "val_dataset = SegmentationDataset(img_folder, seg_folder, batch_size=batch_size, image_size=image_size, file_list=validation_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a batch of data\n",
    "images, segments = train_dataset.__getitem__(0)\n",
    "\n",
    "# Plot the images and their corresponding segments\n",
    "fig, axs = plt.subplots(batch_size, 2, figsize=(10, 50))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    axs[i, 0].imshow(images[i])\n",
    "    axs[i, 0].title.set_text('Image')\n",
    "    axs[i, 1].imshow(np.argmax(segments[i], axis=-1))\n",
    "    axs[i, 1].title.set_text('Segment')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changed the Unet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Dropout\n",
    "\n",
    "def unet(input_size=(256,256,3), n_classes=21):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Dropout(0.1)(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = concatenate([UpSampling2D(size=(2, 2))(conv3), conv2], axis=-1)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(up4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Dropout(0.1)(conv4)\n",
    "\n",
    "    up5 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv1], axis=-1)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(up5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Dropout(0.1)(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    conv6 = Conv2D(n_classes, 1, activation='softmax')(conv5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv6)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the class weights for the generalized dice loss. This is identical to Perrine's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perrine: Compute class weights\n",
    "train_images, train_masks = train_dataset[0]\n",
    "\n",
    "class_weights = np.concatenate((np.arange(21), np.zeros(21)),axis=None).reshape((2, 21)).T\n",
    "#class_weights = np.concatenate((np.arange(20), np.zeros(20)),axis=None).reshape((2, 20)).T  # for no bg\n",
    "\n",
    "n = 0\n",
    "\n",
    "# For each image in the batch\n",
    "for i in range(len(train_images)):\n",
    "    mask = train_masks[i]\n",
    "    mask = np.argmax(mask, axis=-1)\n",
    "\n",
    "    unique, counts = np.unique(mask, return_counts=True)\n",
    "    #unique = unique[1:] # for no bg\n",
    "    #counts = counts[1:] # for no bg\n",
    "    sum = np.sum(counts)\n",
    "\n",
    "    weights = np.asarray((unique, counts/sum*100)).T\n",
    "    \n",
    "    for weight in weights:\n",
    "        class_id = int(weight[0])  # Get the class ID\n",
    "        count_percentage = weight[1]  # Get the count/percentage\n",
    "        \n",
    "        # Find the row in `empty_class` with the matching class ID\n",
    "        row_index = np.where(class_weights[:, 0] == class_id)[0][0]\n",
    "        #row_index = np.where(class_weights[:, 0] == class_id-1)[0][0]   # for no bg\n",
    "        \n",
    "        # Update the second column with the new count/percentage\n",
    "        class_weights[row_index, 1] += count_percentage\n",
    "\n",
    "    n +=1\n",
    "\n",
    "class_weights[:,1] = class_weights[:,1]/n\n",
    "\n",
    "final_weights = class_weights[:,1]/100\n",
    "#final_weights_nobg = class_weights[:,1]/100 # for no bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def generalized_dice_loss(y_true, y_pred, init_weights=final_weights[1:]):\n",
    "    # Number of classes\n",
    "    num_classes = tf.shape(y_pred)[-1]\n",
    "    \n",
    "    # Flatten predictions and labels\n",
    "    y_true_flat = tf.reshape(y_true, (-1, num_classes))\n",
    "    y_pred_flat = tf.reshape(y_pred, (-1, num_classes))\n",
    "    \n",
    "    # Compute class weights based on the frequency of each class\n",
    "    class_weights = 1.0 / (tf.reduce_sum(y_true_flat, axis=0) ** 2)\n",
    "    class_weights = tf.where(tf.math.is_finite(class_weights), class_weights, 1e-10)\n",
    "    print(class_weights)\n",
    "    \n",
    "    # Compute Dice score for each class\n",
    "    numerator = 2.0 * tf.reduce_sum(y_true_flat * y_pred_flat, axis=0)\n",
    "    denominator = tf.reduce_sum(y_true_flat + y_pred_flat, axis=0)\n",
    "    class_dice_scores = (numerator + 1e-10) / (denominator + 1e-10)\n",
    "    \n",
    "    # Multiply Dice scores by class weights\n",
    "    weighted_dice_scores = class_weights * class_dice_scores\n",
    "\n",
    "    # Compute Generalized Dice Loss\n",
    "    dice_loss = 1.0 - tf.reduce_sum(weighted_dice_scores) / (tf.reduce_sum(class_weights) + 1e-10)\n",
    "    \n",
    "    # Penalize incorrect predictions for foreground classes\n",
    "    fg_penalty = 1.0 - class_dice_scores[1:]  # Exclude background class\n",
    "    foreground_loss = tf.reduce_mean(fg_penalty)\n",
    "    #foreground_loss = tf.reduce_mean(init_weights*fg_penalty)\n",
    "    \n",
    "    # Combine Generalized Dice Loss with foreground penalty\n",
    "    total_loss = dice_loss + 0.5 * foreground_loss\n",
    "    \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "Unet = unet((256, 256, 3), 21)  # Assuming 20 classes and image dimensions are 256x256, in RGB \n",
    "Unet.compile(optimizer='adam', loss=generalized_dice_loss, metrics=[metrics.Precision(), metrics.Recall(), metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting the model. Pay attention to the patience in early stopping, I set this to 100 so it doesn't stop training after 4 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Define the early stopping criteria\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=100)  # stop training when 'val_loss' has stopped improving for 3 epochs\n",
    "\n",
    "\n",
    "# Define the model checkpoint criteria\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)  # save only the best model to 'best_model.h5'\n",
    "\n",
    "# Add the model checkpoint callback to the fit function along with early stopping\n",
    "unet_history = Unet.fit(train_dataset, validation_data=val_dataset, epochs=100, callbacks=[early_stop, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 random batches from the training set\n",
    "indices = np.random.choice(len(train_dataset), size=5)\n",
    "\n",
    "for i in indices:\n",
    "    # Get a batch of images and masks from the training set\n",
    "    images, true_masks = train_dataset[i]\n",
    "    \n",
    "    # Select a random image and mask from the batch\n",
    "    idx = np.random.choice(images.shape[0])\n",
    "    image = images[idx]\n",
    "    true_mask = true_masks[idx]\n",
    "    \n",
    "    # Use the model to predict the mask\n",
    "    pred_mask = Unet.predict(image[np.newaxis, ...])[0]\n",
    "    \n",
    "    # Convert the predicted mask to binary predictions\n",
    "    pred_mask = np.argmax(pred_mask, axis=-1)\n",
    "    \n",
    "    # Print the unique classes predicted by the model\n",
    "    unique_classes = np.unique(pred_mask)\n",
    "    print(f'Unique classes predicted: {unique_classes}')\n",
    "    \n",
    "    # Plot the image, the true mask, and the predicted mask\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Image')\n",
    "    axes[1].imshow(np.argmax(true_mask, axis=-1), cmap='nipy_spectral')  # Use a colormap with distinct colors\n",
    "    axes[1].set_title('True Mask')\n",
    "    axes[2].imshow(pred_mask, cmap='nipy_spectral')  # Use the same colormap for the predicted mask\n",
    "    axes[2].set_title('Predicted Mask')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
