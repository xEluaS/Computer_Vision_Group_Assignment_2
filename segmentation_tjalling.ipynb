{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder, img_size, image_files, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.img_size = img_size\n",
    "        self.image_files = image_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.data_folder, 'img', self.image_files[idx])\n",
    "        image = np.load(img_path, allow_pickle=True)\n",
    "\n",
    "        # Load mask\n",
    "        mask_path = os.path.join(self.data_folder, 'seg', self.image_files[idx])\n",
    "        mask = np.load(mask_path, allow_pickle=True)\n",
    "\n",
    "        # Resize image and mask\n",
    "        image = resize(image, self.img_size, anti_aliasing=True)\n",
    "        mask = resize(mask, self.img_size, anti_aliasing=False, order=0)\n",
    "\n",
    "        # Convert image and mask to PyTorch tensors\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, mask)\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.4552, 0.4438, 0.4090], std=[0.2319, 0.2270, 0.2325])\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    normalize  \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_folder = \"/kaggle/input/kul-h02a5a-computer-vision-ga2-2024/train/\"\n",
    "img_size = (256, 256)\n",
    "\n",
    "image_files = sorted(file for file in os.listdir(os.path.join(train_folder, 'img')) if not file.startswith('.'))\n",
    "\n",
    "\n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_folder, img_size, train_files)\n",
    "val_dataset = CustomDataset(train_folder, img_size, val_files)\n",
    "\n",
    "full_dataset = CustomDataset(train_folder, img_size, image_files)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 21\n",
    "learning_rate =0.001\n",
    "num_epochs = 100\n",
    "img_size = (256, 256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),  # Add batch normalization\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),  # Add batch normalization\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 256)  # Increase the number of channels\n",
    "        self.dconv_down2 = double_conv(256, 512)\n",
    "        self.dconv_down3 = double_conv(512, 1024)\n",
    "        self.dconv_down4 = double_conv(1024, 2048)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(1024 + 2048, 1024)\n",
    "        self.dconv_up2 = double_conv(512 + 1024, 512)\n",
    "        self.dconv_up1 = double_conv(256 + 512, 256)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(256, num_classes, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout for regularization\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.dropout(x)  \n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = UNet(num_classes=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "all_files = os.listdir('/kaggle/input/kul-h02a5a-computer-vision-ga2-2024/train/seg')\n",
    "\n",
    "npy_files = [file for file in all_files if file.endswith('.npy')]\n",
    "\n",
    "N = len(npy_files)\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store all labels\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "for i in npy_files:\n",
    "    # Load mask\n",
    "    mask = np.load(f'/kaggle/input/kul-h02a5a-computer-vision-ga2-2024/train/seg/{i}')\n",
    "    \n",
    "    # Add labels to the list\n",
    "    all_labels.extend(np.unique(mask))\n",
    "\n",
    "# Now `all_labels` is a list of all your labels\n",
    "counts = Counter(all_labels)\n",
    "total_count = len(all_labels)\n",
    "\n",
    "class_weights = {cls: total_count / count for cls, count in counts.items()}\n",
    "\n",
    "# If you want to normalize the weights\n",
    "norm_factor = sum(class_weights.values())\n",
    "class_weights = {cls: weight / norm_factor for cls, weight in class_weights.items()}\n",
    "\n",
    "# Convert the dictionary to a list\n",
    "class_weights_list = [class_weights[i] for i in range(len(class_weights))]\n",
    "\n",
    "# Convert the list to a tensor\n",
    "weights = torch.tensor(class_weights_list)\n",
    "\n",
    "# Move weights to the same device as your model\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing some stuff for training. The scheduler adapts the learning rate after 30 epochs so the model focuses more on learning small details instead of trying to learn large features. Weight decay is L2 regularization (I also used dropout in the unet itself, but maybe these can be increased. I suspect the model may be slightly overfitting again after increasing the model size.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the weights in the criterion\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.01, momentum=0.9) # weight decay is L2 regularization\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop below (almost identical to Thibault's, just changed mine to fit the Unet and added the scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(outputs, masks):\n",
    "    # Convert outputs to binary predictions\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = torch.sum(predictions & masks)\n",
    "    union = torch.sum(predictions | masks)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    iou = torch.true_divide(intersection, union + 1e-8)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to the appropriate device\n",
    "    \n",
    "    train_losses = []  # List to store training losses\n",
    "    val_losses = []    # List to store validation losses\n",
    "    train_ious = []    # List to store training IoU\n",
    "    val_ious = []      # List to store validation IoU\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_train_loss = 0.0\n",
    "        running_train_iou = 0.0\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "            for images, masks in train_loader:\n",
    "                # Move images and masks to device\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # outputs = model(images)['out']\n",
    "                outputs = model(images)\n",
    "\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                # Compute IoU\n",
    "                iou = compute_iou(outputs, masks)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update training loss and IoU\n",
    "                running_train_loss += loss.item() * images.size(0)\n",
    "                running_train_iou += iou.item() * images.size(0)\n",
    "                pbar.set_postfix({'Training Loss': running_train_loss / ((pbar.n + 1) * train_loader.batch_size),\n",
    "                                  'Training IoU': running_train_iou / ((pbar.n + 1) * train_loader.batch_size)})\n",
    "                pbar.update()\n",
    "\n",
    "        # Calculate average training loss and IoU\n",
    "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        epoch_train_iou = running_train_iou / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)  # Append to training loss history\n",
    "        train_ious.append(epoch_train_iou)      # Append to training IoU history\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        running_val_loss = 0.0\n",
    "        running_val_iou = 0.0\n",
    "        with torch.no_grad(), tqdm(total=len(val_loader), desc=f'Validation', unit='batch') as pbar:\n",
    "            for val_images, val_masks in val_loader:\n",
    "                val_images = val_images.to(device)\n",
    "                val_masks = val_masks.to(device)\n",
    "\n",
    "                # val_outputs = model(val_images)['out']\n",
    "                val_outputs = model(val_images)\n",
    "                val_loss = criterion(val_outputs, val_masks)\n",
    "                \n",
    "                # Compute IoU\n",
    "                val_iou = compute_iou(val_outputs, val_masks)\n",
    "\n",
    "                running_val_loss += val_loss.item() * val_images.size(0)\n",
    "                running_val_iou += val_iou.item() * val_images.size(0)\n",
    "                pbar.set_postfix({'Validation Loss': running_val_loss / ((pbar.n + 1) * val_loader.batch_size),\n",
    "                                  'Validation IoU': running_val_iou / ((pbar.n + 1) * val_loader.batch_size)})\n",
    "                pbar.update()\n",
    "\n",
    "        # Calculate average validation loss and IoU\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        epoch_val_iou = running_val_iou / len(val_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)  # Append to validation loss history\n",
    "        val_ious.append(epoch_val_iou)      # Append to validation IoU history\n",
    "        scheduler.step() \n",
    "    return train_losses, val_losses, train_ious, val_ious\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_losses, train_ious, val_ious = train(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'unet_adam_weighted_classes{learning_rate}_{num_epochs}epoch.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quickly plotting the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "img_size = (256,256)\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_folder, img_size, image_files):\n",
    "        self.data_folder = data_folder\n",
    "        self.img_size = img_size\n",
    "        self.image_files = sorted(image_files, key=lambda x: int(re.findall(r'\\d+', x)[0])) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.data_folder, 'img', self.image_files[idx])\n",
    "        image = np.load(img_path)\n",
    "\n",
    "        # Resize image\n",
    "        image = resize(image, self.img_size, anti_aliasing=True)\n",
    "\n",
    "        # Convert image to PyTorch tensor\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "\n",
    "        return image\n",
    "\n",
    "# Example usage\n",
    "\n",
    "test_folder = \"/kaggle/input/kul-h02a5a-computer-vision-ga2-2024/test\"\n",
    "\n",
    "# List all image files in the test folder\n",
    "test_image_files = sorted(file for file in os.listdir(os.path.join(test_folder, 'img')) if not file.startswith('.'))\n",
    "\n",
    "# Create TestDataset instance for the test set\n",
    "test_dataset = TestDataset(test_folder, img_size, test_image_files)\n",
    "\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating function to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, test_loader):\n",
    "    device = next(model.parameters()).device  # Get the device of the model's parameters\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "    i=0\n",
    "    with torch.no_grad():\n",
    "        for images_batch in test_loader:\n",
    "            images_batch = images_batch.to(device)  # Move input data to the same device as the model\n",
    "            outputs = model(images_batch)\n",
    "            predictions.append(outputs)\n",
    "            i+=1\n",
    "            print(i)\n",
    "    return torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = make_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \n",
    "               \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "               \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "def plot_test_predictions(test_dataset, test_predictions, num_examples=16):\n",
    "    test_loader = DataLoader(test_dataset, batch_size=num_examples, shuffle=False)\n",
    "    images_batch = next(iter(test_loader))\n",
    "    fig, axes = plt.subplots(num_examples, 2, figsize=(10,50))\n",
    "    for i in range(num_examples):\n",
    "        image = images_batch[i].permute(1, 2, 0).cpu().numpy()\n",
    "        prediction = test_predictions[i].argmax(dim=0).cpu().numpy()  # Convert logits to class predictions\n",
    "        \n",
    "        unique_classes = np.unique(prediction)[1:]\n",
    "        print(unique_classes)\n",
    "        class_labels = [class_names[c] for c in unique_classes]\n",
    "        title = ', '.join(class_labels)\n",
    "        \n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title(f'{title}')\n",
    "\n",
    "        axes[i, 1].imshow(prediction, cmap='jet', vmin=0, vmax=prediction.max())\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title('Predicted Mask')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot some example predictions\n",
    "plot_test_predictions(test_dataset, test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
