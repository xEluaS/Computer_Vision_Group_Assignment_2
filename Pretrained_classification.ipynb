{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import gc\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training data\n",
    "train_df = pd.read_csv('train/train_set.csv', index_col=\"Id\")\n",
    "labels = train_df.columns\n",
    "train_df[\"img\"] = [np.load('train/img/train_{}.npy'.format(idx)) for idx, _ in train_df.iterrows()]\n",
    "train_df[\"seg\"] = [np.load('train/seg/train_{}.npy'.format(idx)) for idx, _ in train_df.iterrows()]\n",
    "print(\"The training set contains {} examples.\".format(len(train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data\n",
    "# test_df = pd.read_csv('test/test_set.csv', index_col=\"Id\")\n",
    "# test_df[\"img\"] = [np.load('test/img/test_{}.npy'.format(idx)) for idx, _ in test_df.iterrows()]\n",
    "# test_df[\"seg\"] = [-1 * np.ones(img.shape[:2], dtype=np.int8) for img in test_df[\"img\"]]\n",
    "# print(\"The test set contains {} examples.\".format(len(test_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take first 20 columns the values of 0 and 1 of the dataframe as labels\n",
    "labels_df = train_df.iloc[:, :20]\n",
    "train_labels = labels_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to resize images\n",
    "def resize_images(img_series, size=(224, 224)):\n",
    "    return img_series.apply(lambda img: cv2.resize(img, size))\n",
    "\n",
    "# Resize and convert the images to a numpy array\n",
    "train_images = np.stack(resize_images(train_df[\"img\"]).values)\n",
    "test_images = np.stack(resize_images(test_df[\"img\"]).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Divide full training set into training and validation set:\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "print(np.max(X_train))\n",
    "X_train = X_train / 255\n",
    "X_val  = X_val / 255\n",
    "print(np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating class weights for the weighted loss\n",
    "weights = np.empty([20, 2])\n",
    "for i in range(20):\n",
    "    weights[i] = compute_class_weight(class_weight=\"balanced\",\n",
    "                               classes=np.array([0, 1]),\n",
    "                               y=y_train[:, i])\n",
    "weights = weights.astype(np.float32)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighed loss function\n",
    "def get_weighted_loss(weights):\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 metric\n",
    "def get_f1(y_true, y_pred):\n",
    "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "  precision = true_positives / (predicted_positives + K.epsilon())\n",
    "  recall = true_positives / (possible_positives + K.epsilon())\n",
    "  f1_val = 2*(precision*recall)/(precision+recall + K.epsilon())\n",
    "  return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING: deletes model and everything\n",
    "# I run this to free up my memory after running a model\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels as floet for calculation in the weighted loss\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PARAMETERS\n",
    "OPT = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# OPT = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "NAME = \"InceptionResNetV2_augmented.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving best weights based on the F1 score\n",
    "save_best = ModelCheckpoint(NAME, monitor='val_get_f1', verbose=0, \n",
    "                              save_best_only=True, mode='max', save_freq=\"epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data augmentation generator for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pretrained model of choice\n",
    "from keras.applications import InceptionResNetV2\n",
    "# from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "\n",
    "base_model = InceptionResNetV2(include_top=False,\n",
    "                                      weights=\"imagenet\",     # \"imagenet\" when transfer learning\n",
    "                                      input_shape=(224, 224, 3),\n",
    "                                      pooling = \"avg\"\n",
    "                                      )\n",
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "predictions = Dense(20, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing pretrained layers + Compiling model\n",
    "\n",
    "# FALSE when transfer learning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=OPT, loss=get_weighted_loss(weights), metrics=[\"accuracy\", get_f1])\n",
    "# For recall and precision metrics\n",
    "# model.compile(optimizer=OPT, loss=get_weighted_loss(weights), metrics=[\"accuracy\", tf.keras.metrics.Precision(name='Precision'), \n",
    "#                        tf.keras.metrics.Recall(name='Recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING (the fully connected added layers)\n",
    "\n",
    "history = model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data = validation_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE),\n",
    "                    shuffle=True,\n",
    "                    callbacks=[save_best]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1 score\n",
    "f1 = history.history['get_f1']\n",
    "val_f1 = history.history['val_get_f1']\n",
    "epochs = range(1, len(f1) + 1)\n",
    "plt.plot(epochs, f1, 'y', label='Training F1')\n",
    "plt.plot(epochs, val_f1, 'r', label='Validation F1')\n",
    "plt.title('Training and validation F1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using the precision and recall metrics\n",
    "\n",
    "# Plot precision\n",
    "precision = history.history['Precision']\n",
    "val_precision = history.history['val_Precision']\n",
    "epochs = range(1, len(precision) + 1)\n",
    "plt.plot(epochs, precision, 'y', label='Training precision')\n",
    "plt.plot(epochs, val_precision, 'r', label='Validation precision')\n",
    "plt.title('Training and validation precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using the precision and recall metrics\n",
    "\n",
    "# Plot recall\n",
    "recall = history.history['Recall']\n",
    "val_recall = history.history['val_Recall']\n",
    "epochs = range(1, len(recall) + 1)\n",
    "plt.plot(epochs, recall, 'y', label='Training recall')\n",
    "plt.plot(epochs, val_recall, 'r', label='Validation recall')\n",
    "plt.title('Training and validation recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot recall-precision trade-off\n",
    "# Used to determine the threshold (manually)\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (5,5))\n",
    "ax.set_title(\"Precision recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_xlim(xmin=0, xmax=1)\n",
    "ax.set_ylim(ymin=0, ymax=1)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for threshold in np.arange(0, 1.1, 0.1):\n",
    "  y_pred_val = model.predict(X_val)\n",
    "  y_pred_val[y_pred_val>=threshold] = 1\n",
    "  y_pred_val[y_pred_val<threshold] = 0\n",
    "  p = precision_score(y_val, y_pred_val, average='samples', zero_division=0)\n",
    "  r = recall_score(y_val, y_pred_val, average='samples')\n",
    "  ax.annotate(str(round(threshold,2)), (r, p))\n",
    "  x.append(r)\n",
    "  y.append(p)\n",
    "  \n",
    "ax.plot(x, y)\n",
    "ax.lines[-1].set_label(NAME.split(\"_\")[0])\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall - Precision - F1-score based on threshold\n",
    "# F1-scores for each class\n",
    "\n",
    "\n",
    "# SET THE THRESHOLD\n",
    "threshold = 0.70\n",
    "\n",
    "\n",
    "\n",
    "print(f'\\n-------- Metrics for Pretrained {NAME.split(\"_\")[0]}:---------\\n ')\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "y_pred_val[y_pred_val>=threshold] = 1\n",
    "y_pred_val[y_pred_val<threshold] = 0\n",
    "\n",
    "print('Precision: ', precision_score(y_val, y_pred_val, average='samples', zero_division=0)) \n",
    "print('Recall: ', recall_score(y_val, y_pred_val, average='samples')) \n",
    "print('F1-score: ', f1_score(y_val, y_pred_val, average='samples'), '\\n') \n",
    "\n",
    "print('Per class F1 score: ')\n",
    "f1_scores = f1_score(y_val, y_pred_val, average=None)\n",
    "for i in range(len(f1_scores)):\n",
    "  print(list(sorted(labels))[i], round(f1_scores[i],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model if it was not trained\n",
    "# model.load_weights(\"NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on validation set\n",
    "\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "\n",
    "# Using random images from validation set, change numb to specific number if wanted\n",
    "numb = np.random.randint(0, len(X_val))\n",
    "\n",
    "\n",
    "print(f\"Predicted class probabilities: {preds[numb]}\")\n",
    "print(f\"Ground truth: {y_val[numb]}\")\n",
    "# result = [num if num > 0.3 else 0 for num in preds[numb]]\n",
    "# print(result)\n",
    "\n",
    "mask = [1 if num > threshold else 0 for num in preds[numb]]\n",
    "max_class = lbls[np.argmax(preds[numb])]\n",
    "true_idx = np.argwhere(y_val[numb] == 1).flatten()\n",
    "true_classes = []\n",
    "for idx in true_idx:\n",
    "    true_classes.append(lbls[idx])\n",
    "\n",
    "c = y_val[numb] * np.array(preds[numb])\n",
    "\n",
    "plt.imshow(X_val[numb])\n",
    "plt.title(\" - \".join([lbl for i, lbl in enumerate(lbls) if mask[i] == 1]))\n",
    "plt.text(100, 25, f\"MAX: {max_class}, {np.format_float_positional(np.max(preds[numb]), precision=2)}\", color=\"red\", fontsize=15)\n",
    "plt.text(100, 50, f\"CORRECT: {' '.join(true_classes)}\", color=\"blue\", fontsize=15)\n",
    "plt.text(100, 75, f\"prob: {'   '.join([np.format_float_positional(score, precision=2) for score in c[np.nonzero(c)]])}\", color=\"blue\", fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
